
@article{chellapilla_evolving_1999,
	title = {Evolving {Neural} {Networks} to {Play} {Checkers} without {Expert} {Knowledge}},
	volume = {10},
	issn = {10459227},
	url = {http://ieeexplore.ieee.org/abstract/document/809083},
	doi = {10.1109/72.809083},
	abstract = {— An experiment was conducted where neural net-works compete for survival in an evolving population based on their ability to play checkers. More specifically, multilayer feedforward neural networks were used to evaluate alternative board positions and games were played using a minimax search strategy. At each generation, the extant neural networks were paired in competitions and selection was used to eliminate those that performed poorly relative to other networks. Offspring neural networks were created from the survivors using random variation of all weights and bias terms. After a series of 250 generations, the best-evolved neural network was played against human opponents in a series of 90 games on an internet website. The neural network was able to defeat two expert-level players and played to a draw against a master. The final rating of the neural network placed it in the " Class A " category using a standard rating system. Of particular importance in the design of the experiment was the fact that no features beyond the piece differential were given to the neural networks as a priori knowledge. The process of evolution was able to extract all of the additional information required to play at this level of competency. It accomplished this based almost solely on the feedback offered in the final aggregated outcome of each game played (i.e., win, lose, or draw). This procedure stands in marked contrast to the typical artifice of explicitly injecting expert knowledge into a game-playing program. Index Terms—Alpha–beta search, checkers, evolutionary com-putation, feedforward neural networks, game playing.},
	number = {6},
	journal = {IEEE Transactions on Neural Networks},
	author = {Chellapilla, Kumar and Fogel, David},
	year = {1999},
	pmid = {18252639},
	pages = {1382--1391},
	file = {Attachment:/home/tn/Zotero/storage/UIECZQLX/Chellapilla, Fogel - 1999 - Evolving Neural Networks to Play Checkers without Expert Knowledge.pdf:application/pdf}
}

@phdthesis{allsop_artficial_2013,
	title = {Artficial {Intelligence} {Techniques} {Applied} {To} {Draughts} {Artificial} {Intelligence} {Techniques} {Applied} {To} {Draughts}},
	school = {Durham University},
	author = {Allsop, Daniel (Durham University)},
	year = {2013},
	file = {Attachment:/home/tn/Zotero/storage/VN5S9LCQ/Allsop - 2013 - Artficial Intelligence Techniques Applied To Draughts Artificial Intelligence Techniques Applied To Draughts.pdf:application/pdf}
}

@article{thesis_combining_1994,
	title = {Combining {Genetic} {Algorithms} and {Neural} {Networks} : {The} {Encoding} {Problem}},
	abstract = {Neural networks and genetic algorithms demonstrate powerful problem solving ability. They are based on quite simple principles, but take advantage of their mathematical nature: non-linear iteration. Neural networks with backpropagation learning showed results by searching for various kinds of functions. However, the choice of the basic parameter (network topology, learning rate, initial weights) often already determines the success of the training process. The selection of these parame- ter follow in practical use rules of thumb, but their value is at most arguable. Genetic algorithms are global search methods, that are based on princi- ples like selection, crossover and mutation. This thesis examines how genetic algorithms can be used to optimize the network topology etc. of neural net- works. It investigates, how various encoding strategies influence the GA/NN synergy. They are evaluated according to their performance on academic and practical problems of different complexity.},
	number = {December},
	journal = {Thesis ANN p 67},
	author = {Thesis, a},
	year = {1994},
	pages = {1--67},
	file = {Attachment:/home/tn/Zotero/storage/NUFQSZFS/Thesis - 1994 - Combining Genetic Algorithms and Neural Networks The Encoding Problem.pdf:application/pdf}
}

@article{perez_apply_nodate,
	title = {Apply genetic algorithm to the learning phase of a neural network},
	abstract = {Natural networks have been used during several years to solve classifica-tion problems. The performance of a neural network depends directly on the design of the hidden layers, and in the calculation of the weights that connect the different nodes. On this project, the structure of the hidden layer is not modified, as the interest lies only on the calculation of the weights of the system. In order to obtain a feasible result, the weights of the neural network are calculated due a function cost. A genetic algo-rithm approach is presented and compared with the gradient descent in failure rate and time to obtain a solution.},
	author = {Perez, Sergi},
	file = {Attachment:/home/tn/Zotero/storage/YLCQSUUZ/Perez - Unknown - Apply genetic algorithm to the learning phase of a neural network.pdf:application/pdf}
}

@article{samuel_studies_2000,
	title = {Some studies in machine learning using the game of checkers},
	volume = {44},
	issn = {0018-8646},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5389202%5Cnpapers3://publication/doi/10.1147/rd.441.0206},
	doi = {10.1147/rd.441.0206},
	abstract = {AL Samuel Some Studies in Machine Learning Using the Game of Checkers Abstract: Two machine - learning procedures have been investigated in some detail using the game of checkers . Enough work has been done to verify the fact that a computer can be ... \${\textbackslash}backslash\$n},
	number = {1.2},
	journal = {IBM Journal of Research and Development},
	author = {Samuel, A L},
	year = {2000},
	pages = {206--226},
	file = {Attachment:/home/tn/Zotero/storage/56UN45RQ/Samuel - 2000 - Some studies in machine learning using the game of checkers.pdf:application/pdf}
}

@book{mullins_checkers_2007,
	title = {Checkers 'solved' after years of number crunching},
	url = {https://www.newscientist.com/article/dn12296-checkers-solved-after-years-of-number-crunching/ http://www.newscientisttech.com/article/dn12296-checkers-solved-after-years-of-number-crunching.html},
	author = {Mullins, Justin},
	year = {2007}
}

@article{lorentz_using_2016,
	title = {Using evaluation functions in {Monte}-{Carlo} {Tree} {Search}},
	volume = {644},
	issn = {03043975},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397516302717},
	doi = {10.1016/j.tcs.2016.06.026},
	language = {en},
	urldate = {2018-01-06},
	journal = {Theoretical Computer Science},
	author = {Lorentz, Richard},
	month = sep,
	year = {2016},
	pages = {106--113},
	file = {1-s2.0-S0304397516302717-main.pdf:/home/tn/Zotero/storage/LF6KY5WA/1-s2.0-S0304397516302717-main.pdf:application/pdf}
}

@article{browne_survey_2012,
	title = {A {Survey} of {Monte} {Carlo} {Tree} {Search} {Methods}},
	volume = {4},
	issn = {1943-068X},
	doi = {10.1109/TCIAIG.2012.2186810},
	abstract = {Monte Carlo tree search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difficult problem of computer Go, but has also proved beneficial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the first five years of MCTS research. We outline the core algorithm's derivation, impart some structure on the many variations and enhancements that have been proposed, and summarize the results from the key game and nongame domains to which MCTS methods have been applied. A number of open research questions indicate that the field is ripe for future work.},
	number = {1},
	journal = {IEEE Transactions on Computational Intelligence and AI in Games},
	author = {Browne, C. B. and Powley, E. and Whitehouse, D. and Lucas, S. M. and Cowling, P. I. and Rohlfshagen, P. and Tavener, S. and Perez, D. and Samothrakis, S. and Colton, S.},
	month = mar,
	year = {2012},
	keywords = {Artificial intelligence, Artificial intelligence (AI), bandit-based methods, computer Go, Computers, Decision theory, game search, game theory, Game theory, Games, key game, Markov processes, MCTS research, Monte Carlo methods, Monte Carlo tree search (MCTS), Monte carlo tree search methods, nongame domains, random sampling generality, tree searching, upper confidence bounds (UCB), upper confidence bounds for trees (UCT)},
	pages = {1--43},
	file = {IEEE Xplore Abstract Record:/home/tn/Zotero/storage/X2QAE6CV/6145622.html:text/html}
}