@book{Mullins2007,
author = {Mullins, Justin},
booktitle = {New Scientist},
title = {{Checkers 'solved' after years of number crunching}},
url = {https://www.newscientist.com/article/dn12296-checkers-solved-after-years-of-number-crunching/ http://www.newscientisttech.com/article/dn12296-checkers-solved-after-years-of-number-crunching.html},
year = {2007}
}
@article{Lai2015,
abstract = {This report presents Giraffe, a chess engine that uses self-play to discover all its domain-specific knowledge, with minimal hand-crafted knowledge given by the programmer. Unlike previous attempts using machine learning only to perform parameter-tuning on hand-crafted evaluation functions, Giraffe's learning system also performs automatic feature extraction and pattern recognition. The trained evaluation function performs comparably to the evaluation functions of state-of-the-art chess engines - all of which containing thousands of lines of carefully hand-crafted pattern recognizers, tuned over many years by both computer chess experts and human chess masters. Giraffe is the most successful attempt thus far at using end-to-end machine learning to play chess.},
archivePrefix = {arXiv},
arxivId = {1509.01549},
author = {Lai, Matthew},
eprint = {1509.01549},
file = {:home/me/Dropbox/Documents/Project/Research Papers/giraffe.pdf:pdf},
number = {September},
title = {{Giraffe: Using Deep Reinforcement Learning to Play Chess}},
url = {http://arxiv.org/abs/1509.01549},
year = {2015}
}
@article{Xie2017,
abstract = {The deep Convolutional Neural Network (CNN) is the state-of-the-art solution for large-scale visual recognition. Following basic principles such as increasing the depth and constructing highway connections, researchers have manually designed a lot of fixed network structures and verified their effectiveness. In this paper, we discuss the possibility of learning deep network structures automatically. Note that the number of possible network structures increases exponentially with the number of layers in the network, which inspires us to adopt the genetic algorithm to efficiently traverse this large search space. We first propose an encoding method to represent each network structure in a fixed-length binary string, and initialize the genetic algorithm by generating a set of randomized individuals. In each generation, we define standard genetic operations, e.g., selection, mutation and crossover, to eliminate weak individuals and then generate more competitive ones. The competitiveness of each individual is defined as its recognition accuracy, which is obtained via training the network from scratch and evaluating it on a validation set. We run the genetic process on two small datasets, i.e., MNIST and CIFAR10, demonstrating its ability to evolve and find high-quality structures which are little studied before. These structures are also transferrable to the large-scale ILSVRC2012 dataset.},
archivePrefix = {arXiv},
arxivId = {1703.01513},
author = {Xie, Lingxi and Yuille, Alan},
eprint = {1703.01513},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Printed/1703.01513.pdf:pdf},
title = {{Genetic CNN}},
url = {http://arxiv.org/abs/1703.01513},
year = {2017}
}
@article{Cobbe,
author = {Cobbe, Karl and Lee, Paul and Gomez-Emilsson, A},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Printed/CobbeLeeGomez-AcceleratingCheckersAIEvolution.pdf:pdf},
journal = {Cs229.Stanford.Edu},
pages = {2--5},
title = {{Accelerating Checkers AI Evolution}},
url = {http://cs229.stanford.edu/proj2011/CobbeLeeGomez-AcceleratingCheckersAIEvolution.pdf}
}
@article{Samuel2000,
abstract = {AL Samuel Some Studies in Machine Learning Using the Game of Checkers Abstract: Two machine - learning procedures have been investigated in some detail using the game of checkers . Enough work has been done to verify the fact that a computer can be ... $\backslash$n},
author = {Samuel, A L},
doi = {10.1147/rd.441.0206},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Printed/05389202.pdf:pdf},
isbn = {0018-8646},
issn = {0018-8646},
journal = {IBM Journal of Research and Development},
number = {1.2},
pages = {206--226},
title = {{Some studies in machine learning using the game of checkers}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5389202{\%}5Cnpapers3://publication/doi/10.1147/rd.441.0206},
volume = {44},
year = {2000}
}
@article{Fogel2000,
author = {Fogel, David B},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Printed/p20-fogel.pdf:pdf},
title = {{Evolving a Checkers Player}},
year = {2000}
}
@article{Back1997,
author = {B{\"{a}}ck, T},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Printed/Fogel-1997-Complexity.pdf:pdf},
journal = {65.44.200.132},
pages = {26--27},
title = {{Fogel on B{\"{a}}ck}},
url = {http://65.44.200.132/Library/1997/Complexity{\_}1997{\_}FogelReview.pdf},
year = {1997}
}
@article{Kusiak2007,
abstract = {A new method of genetic evolution of linear and nonlinear evaluation functions in the game of checkers is presented. Several practical issues concerning application of genetic algorithms for this task are pointed out and discussed. Experimental results confirm that proposed approach leads to efficient evaluation functions comparable to the ones used in some of commercial applications. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Kusiak, Magdalena and Walezedik, Karol and Jacek, Mandziuk},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Printed/Evolutionary Approach to the game of Checkers.pdf:pdf},
isbn = {9783540715894},
issn = {03029743},
number = {48 22},
pages = {600--661},
title = {{Evolutionary approach to the game of checkers}},
volume = {1},
year = {2007}
}
@article{Toledo-Marin2016,
abstract = {A checkers-like model game with a simplified set of rules is studied through extensive simulations of agents with different expertise and strategies. The introduction of complementary strategies, in a quite general way, provides a tool to mimic the basic ingredients of a wide scope of real games. We find that only for the player having the higher offensive expertise (the dominant player ), maximizing the offensive always increases the probability to win. For the non-dominant player, interestingly, a complete minimization of the offensive becomes the best way to win in many situations, depending on the relative values of the defense expertise. Further simulations on the interplay of defense expertise were done separately, in the context of a fully-offensive scenario, offering a starting point for analytical treatments. In particular, we established that in this scenario the total number of moves is defined only by the player with the lower defensive expertise. We believe that these results stand for a first step towards a new way to improve decisions-making in a large number of zero-sum real games.},
archivePrefix = {arXiv},
arxivId = {1608.07223},
author = {Toledo-Mar{\'{i}}n, J. Quetzalc{\'{o}}atl and D{\'{i}}az-M{\'{e}}ndez, Rogelio and Mussot, Marcelo del Castillo},
doi = {10.1142/S0219198917500049},
eprint = {1608.07223},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Printed/is good defense the best offence.pdf:pdf},
issn = {02191989},
pages = {1--12},
title = {{Is a good offensive always the best defense?}},
url = {http://arxiv.org/abs/1608.07223},
year = {2016}
}
@article{Al-Khateeb2012,
abstract = {Intuitively it would seem to be the case that any learning algorithm would perform better if it was allowed to search deeper in the game tree. However, there has been some discussion as to whether the evaluation function or the depth of the search is the main contributory factor in the performance of the player. There has been some evidence suggesting that look-ahead (i.e. depth of search) is particularly important. In this work we provide a rigorous set of experiments, which support this view. We believe this is the first time such an intensive study has been carried out for evolutionary checkers. Our experiments show that increasing the depth of a look-ahead has significant improvements to the performance of the checkers program and has a significant effect on its learning abilities.},
author = {Al-Khateeb, Belal and Kendall, Graham},
doi = {10.1007/s11390-012-1280-6},
file = {:home/me/Dropbox/Documents/Project/Research Papers/s11390-012-1280-6.pdf:pdf},
isbn = {9781424478347},
issn = {10009000},
journal = {Journal of Computer Science and Technology},
keywords = {Evolutionary checkers,Look-ahead depth,Neural network},
number = {5},
pages = {996--1006},
title = {{Effect of look-ahead depth in evolutionary checkers}},
volume = {27},
year = {2012}
}
@article{Nguyen2004,
abstract = {The artificial neural network (ANN) methodology has been used in various$\backslash$ntime series prediction applications. However, the accuracy of a$\backslash$nneural network model may be seriously compromised when it is used$\backslash$nrecursively for making long-term multi-step predictions. This study$\backslash$npresents a method using multiple ANNs to make a long term time series$\backslash$nprediction. A multiple neural network (MNN) model is a group of$\backslash$nneural networks that work together to solve a problem. In the proposed$\backslash$nMNN approach, each component neural network makes forecasts at a$\backslash$ndifferent length of time ahead. The MNN method was applied to the$\backslash$nproblem of forecasting an hourly customer demand for gas at a compression$\backslash$nstation in Saskatchewan, Canada. The results showed that a MNN model$\backslash$nperformed better than a single ANN model for long term prediction.},
author = {Nguyen, Hanh H. and Chan, Christine W.},
doi = {10.1007/s00521-003-0390-z},
file = {:home/me/Dropbox/Documents/Project/Research Papers/multiple neural networks 1.pdf:pdf},
issn = {09410643},
journal = {Neural Computing and Applications},
keywords = {Multiple neural networks,Time series forecasting},
number = {1},
pages = {90--98},
title = {{Multiple neural networks for a long term time series forecast}},
volume = {13},
year = {2004}
}
@phdthesis{Al-Khateeb2011,
abstract = {the game of checkers by introducing a league structure into the learning phase of a system based on Blondie24. We believe that this helps eliminate some of the randomness in the evolution. The best player obtained is tested against an evolutionary checkers program based on Blondie24. The results obtained are promising. In addition, we introduce an individual and social learning mechanism into the learning phase of the evolutionary checkers system. The best player obtained is tested against an implementation of an evolutionary checkers program, and also against a player, which utilises a round robin tournament. The results are promising.},
author = {Al-Khateeb, Belal},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Thesis.pdf:pdf},
pages = {204},
school = {University of Nottingham},
title = {{Investigating evolutionary checkers by incorporating individual and social learning , N-tuple systems and a round robin tournament}},
year = {2011}
}
@article{Al-Khateeb2009,
author = {Al-Khateeb, Belal and Kendall, Graham},
doi = {10.1109/CIG.2009.5286487},
file = {:home/me/Dropbox/Documents/Project/Research Papers/05286487.pdf:pdf},
isbn = {9781424448159},
journal = {CIG2009 - 2009 IEEE Symposium on Computational Intelligence and Games},
number = {0},
pages = {112--116},
title = {{Introducing a round robin tournament into blondie24}},
volume = {44},
year = {2009}
}
@article{Stanley2002,
abstract = {The ventral visual pathway implements object recognition and categorization in a hierarchy of processing areas with neuronal selectivities of increasing complexity. The presence of massive feedback connections within this hierarchy raises the possibility that normal visual processing relies on the use of computational loops. It is not known, however, whether object recognition can be performed at all without such loops (i.e., in a purely feed-forward mode). By analyzing the time course of reaction times in a masked natural scene categorization paradigm, we show that the human visual system can generate selective motor responses based on a single feed-forward pass. We confirm these results using a more constrained letter discrimination task, in which the rapid succession of a target and mask is actually perceived as a distractor. We show that a masked stimulus presented for only 26 msecand often not consciously perceivedcan fully determine the earliest selective motor responses: The neural representations of the stimulus and mask are thus kept separated during a short period corresponding to the feedforward sweep. Therefore, feedback loops do not appear to be mandatory for visual processing. Rather, we found that such loops allow the masked stimulus to reverberate in the visual system and affect behavior for nearly 150 msec after the feed-forward sweep.},
archivePrefix = {arXiv},
arxivId = {1407.0576},
author = {Stanley, Kenneth O. and Miikkulainen, Risto},
doi = {10.1162/106365602320169811},
eprint = {1407.0576},
file = {:home/me/Dropbox/Documents/Project/Research Papers/stanley.ec02.pdf:pdf},
isbn = {1063-6560},
issn = {1063-6560},
journal = {Evolutionary Computation},
number = {2},
pages = {99--127},
pmid = {12180173},
title = {{Evolving Neural Networks through Augmenting Topologies}},
url = {http://www.mitpressjournals.org/doi/10.1162/106365602320169811},
volume = {10},
year = {2002}
}
@article{Elyasaf2014,
author = {Elyasaf, Achiya},
file = {:home/me/Dropbox/Documents/Project/Research Papers/10.1.1.702.7054.pdf:pdf},
number = {October},
title = {{Evolving Hyper-Heuristics using Genetic Programming}},
year = {2014}
}
@article{Al-khateeb2012,
author = {Al-khateeb, Belal and Kendall, Graham},
file = {:home/me/Dropbox/Documents/Project/Research Papers/06243194.pdf:pdf},
journal = {IEEE Transactions on Computational Intelligence and AI In Games},
number = {4},
pages = {258--269},
title = {{Introducing Individual and Social learning into Evolutionary Checkers}},
volume = {4},
year = {2012}
}
@article{Al-khateeb,
author = {Al-khateeb, Belal and Kendall, Graham},
file = {:home/me/Dropbox/Documents/Project/Research Papers/05625582.pdf:pdf},
title = {{The Importance of a Piece Difference Feature to Blondie24}}
}
@article{Schaeffer1996,
abstract = {In 1962, a checkers-playing program written by Arthur Samuel defeated a self-proclaimed master player, creating a sensation at the time for the fledgling field of computer science called artificial intelligence. The historical record refers to this event as having solved the game of checkers. This paper discusses achieving three different levels of solving the game: publicly (as evidenced by Samuel's results), practically (by the checkers program Chinook , the best player in the world) and provably (by consid-ering the 5 × 10 20 positions in the search space). The latter definition may be attainable in the near future.},
author = {Schaeffer, Jonathan and Lake, Robert},
file = {:home/me/Dropbox/Documents/Project/Research Papers/chinook.pdf:pdf},
journal = {Games of No Chance},
pages = {119--133},
title = {{Solving the Game of Checkers}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=cYB-ra2T8i4C{\&}oi=fnd{\&}pg=PA119{\&}dq=Solving+the+Game+of+Checkers{\&}ots=H0lLXM9{\_}gp{\&}sig=0DO68kXG6UsGhvhLfW1a5vqz3n0},
volume = {29},
year = {1996}
}
@article{Silver2017,
abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo.},
author = {Silver, David and Schrittweiser, Julian and Simonyan, Karen},
doi = {10.1038/nature24270},
file = {:home/me/Dropbox/Documents/Project/Research Papers/agz{\_}unformatted{\_}nature.pdf:pdf},
isbn = {3013372370},
issn = {0028-0836},
journal = {Nature},
pages = {354--359},
pmid = {29052630},
title = {{Mastering the game of Go without human knowledge}},
url = {https://www.nature.com/nature/journal/v550/n7676/full/nature24270.html},
volume = {550},
year = {2017}
}
@article{Perez,
abstract = {Natural networks have been used during several years to solve classifica-tion problems. The performance of a neural network depends directly on the design of the hidden layers, and in the calculation of the weights that connect the different nodes. On this project, the structure of the hidden layer is not modified, as the interest lies only on the calculation of the weights of the system. In order to obtain a feasible result, the weights of the neural network are calculated due a function cost. A genetic algo-rithm approach is presented and compared with the gradient descent in failure rate and time to obtain a solution.},
author = {Perez, Sergi},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Printed/sperez1{\_}GANN.pdf:pdf},
title = {{Apply genetic algorithm to the learning phase of a neural network}}
}
@article{Boonzaaier2017,
author = {Boonzaaier, Daniel},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Printed/projterm1.pdf:pdf},
number = {April},
title = {{Training a Neural Network for Checkers}},
year = {2017}
}
@book{Pappa2014,
abstract = {The fields of machine meta-learning and$\backslash$nhyper-heuristic optimisation have developed mostly$\backslash$nindependently of each other, although evolutionary$\backslash$nalgorithms (particularly genetic programming) have$\backslash$nrecently played an important role in the development of$\backslash$nboth fields. Recent work in both fields shares a common$\backslash$ngoal, that of automating as much of the algorithm$\backslash$ndesign process as possible. In this paper we first$\backslash$nprovide a historical perspective on automated algorithm$\backslash$ndesign, and then we discuss similarities and$\backslash$ndifferences between meta-learning in the field of$\backslash$nsupervised machine learning (classification) and$\backslash$nhyper-heuristics in the field of optimisation. This$\backslash$ndiscussion focuses on the dimensions of the problem$\backslash$nspace, the algorithm space and the performance measure,$\backslash$nas well as clarifying important issues related to$\backslash$ndifferent levels of automation and generality in both$\backslash$nfields. We also discuss important research directions,$\backslash$nchallenges and foundational issues in meta-learning and$\backslash$nhyper-heuristic research. It is important to emphasise$\backslash$nthat this paper is not a survey, as several surveys on$\backslash$nthe areas of meta-learning and hyper-heuristics$\backslash$n(separately) have been previously published. The main$\backslash$ncontribution of the paper is to contrast meta-learning$\backslash$nand hyper-heuristics methods and concepts, in order to$\backslash$npromote awareness and cross-fertilisation of ideas$\backslash$nacross the (by and large, non-overlapping) different$\backslash$ncommunities of meta-learning and hyper-heuristic$\backslash$nresearchers. We hope that this cross-fertilisation of$\backslash$nideas can inspire interesting new research in both$\backslash$nfields and in the new emerging research area which$\backslash$nconsists of integrating those fields.},
author = {Pappa, Gisele L. and Ochoa, Gabriela and Hyde, Matthew R. and Freitas, Alex A. and Woodward, John and Swan, Jerry},
booktitle = {Genetic Programming and Evolvable Machines},
doi = {10.1007/s10710-013-9186-9},
file = {:home/me/Dropbox/Documents/Project/Research Papers/GPEM-J-2014-Pappa.pdf:pdf},
isbn = {5531340958},
issn = {13892576},
keywords = {Automated algorithm design,Genetic programming,Hyper-heuristics,Meta-learning},
number = {1},
pages = {3--35},
title = {{Contrasting meta-learning and hyper-heuristic research: The role of evolutionary algorithms}},
volume = {15},
year = {2014}
}
@article{Thesis1994,
abstract = {Neural networks and genetic algorithms demonstrate powerful problem solving ability. They are based on quite simple principles, but take advantage of their mathematical nature: non-linear iteration. Neural networks with backpropagation learning showed results by searching for various kinds of functions. However, the choice of the basic parameter (network topology, learning rate, initial weights) often already determines the success of the training process. The selection of these parame- ter follow in practical use rules of thumb, but their value is at most arguable. Genetic algorithms are global search methods, that are based on princi- ples like selection, crossover and mutation. This thesis examines how genetic algorithms can be used to optimize the network topology etc. of neural net- works. It investigates, how various encoding strategies influence the GA/NN synergy. They are evaluated according to their performance on academic and practical problems of different complexity.},
author = {Thesis, a},
file = {:home/me/Dropbox/Documents/Project/Research Papers/combining ga and nn.pdf:pdf},
journal = {Thesis ANN p 67},
number = {December},
pages = {1--67},
title = {{Combining Genetic Algorithms and Neural Networks : The Encoding Problem}},
year = {1994}
}
@book{Schaeffer1997,
author = {Schaeffer, Jonathan},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Longreads/Jonathan Schaeffer auth. One Jump Ahead Challenging Human Supremacy in Checkers.pdf:pdf},
isbn = {9780387765754},
pages = {496},
title = {{One Jump Ahead}},
year = {1997}
}
@book{Fogel2001,
abstract = {This chapter examines the expertise of Blondie24 in playing games. Blondie24 played more than 110 out of 165 on zone.com for six weeks. Overall, she played 84 games as red and 81 as white in which her average rating was 2,045.85 with a standard deviation of 33.94. After 165 games, the trajectory had stabilized, and Blondie was clearly declared an expert. As a result, Blondie's got a place in top 500 out of 12,000 registered players on zone.com. Blondie was better than 99.61 percent of all the rated players at the website. Blondie made a remarkable 84 wins, 20 draws, and 11 losses when played against the opponents who were rated below 2,000. Moreover, Blondie had 10 wins, 12 draws, and 22 losses when played with the opponents rated from 2,000 to 2,200. When Blondie played with other professionals, she won 31.25 percent of her games.},
author = {Fogel, David B},
booktitle = {Blondie24},
doi = {10.1016/B978-155860783-5/50016-7},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Longreads/[David{\_}B.{\_}Fogel]{\_}Blondie24{\_}Playing{\_}at{\_}the{\_}Edge{\_}of(b-ok.org).pdf:pdf},
isbn = {9781558607835},
issn = {13892576},
pages = {273--298},
pmid = {12488991},
title = {{Blondie24: Playing at the Edge of AI}},
url = {http://www.sciencedirect.com/science/article/pii/B9781558607835500167},
year = {2001}
}
@phdthesis{Allsop2013,
author = {Allsop, Daniel (Durham University)},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Longreads/Masters{\_}Thesis{\_}Final.pdf:pdf},
school = {Durham University},
title = {{Artficial Intelligence Techniques Applied To Draughts Artificial Intelligence Techniques Applied To Draughts}},
year = {2013}
}
@article{Chellapilla1999,
abstract = {— An experiment was conducted where neural net-works compete for survival in an evolving population based on their ability to play checkers. More specifically, multilayer feedforward neural networks were used to evaluate alternative board positions and games were played using a minimax search strategy. At each generation, the extant neural networks were paired in competitions and selection was used to eliminate those that performed poorly relative to other networks. Offspring neural networks were created from the survivors using random variation of all weights and bias terms. After a series of 250 generations, the best-evolved neural network was played against human opponents in a series of 90 games on an internet website. The neural network was able to defeat two expert-level players and played to a draw against a master. The final rating of the neural network placed it in the " Class A " category using a standard rating system. Of particular importance in the design of the experiment was the fact that no features beyond the piece differential were given to the neural networks as a priori knowledge. The process of evolution was able to extract all of the additional information required to play at this level of competency. It accomplished this based almost solely on the feedback offered in the final aggregated outcome of each game played (i.e., win, lose, or draw). This procedure stands in marked contrast to the typical artifice of explicitly injecting expert knowledge into a game-playing program. Index Terms—Alpha–beta search, checkers, evolutionary com-putation, feedforward neural networks, game playing.},
author = {Chellapilla, Kumar and Fogel, David B D.B. David B.},
doi = {10.1109/72.809083},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Printed/TNNKChellapillaAndDBFogelText.pdf:pdf},
isbn = {1045-9227},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
number = {6},
pages = {1382--1391},
pmid = {18252639},
title = {{Evolving Neural Networks to Play Checkers without Expert Knowledge}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Evolving+neural+networks+to+play+checkers+without+expert+knowledge{\#}8},
volume = {10},
year = {1999}
}
@article{Klambauer2017,
abstract = {Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: github.com/bioinf-jku/SNNs.},
archivePrefix = {arXiv},
arxivId = {1706.02515},
author = {Klambauer, G{\"{u}}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
doi = {1706.02515},
eprint = {1706.02515},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Longreads/1706.02515.pdf:pdf},
journal = {arXiv},
title = {{Self-Normalizing Neural Networks}},
url = {http://arxiv.org/abs/1706.02515},
year = {2017}
}
@article{Franken2003,
abstract = {This paper investigates the effectiveness of various particle swarm optimiser structures to learn how to play the game of checkers. Co-evolutionary techniques are used to train the game playing agents. Performance is compared against a player making moves at random. Initial experimental results indicate definite advantages in using certain information sharing structures and swarm size configurations to successfully learn the game of checkers.},
author = {Franken, Nelis and Engelbrecht, Andries P.},
doi = {10.1109/CEC.2003.1299580},
file = {:home/me/Dropbox/Documents/Project/Research Papers/Longreads/01299580.pdf:pdf},
isbn = {0-7803-7804-0},
journal = {2003 Congress on Evolutionary Computation, CEC 2003 - Proceedings},
pages = {234--241},
title = {{Comparing PSO structures to learn the game of checkers from zero knowledge}},
volume = {1},
year = {2003}
}
